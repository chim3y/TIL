## 5. Classification

### 5.1 Naive bayes

- term
    - conditional probability / posterior probability / prior probability / likelihood
- not naive : 모든 predictive 가 같은 레코드를 찾고, 해당 레코드들이 가장 많이 속한 클래스를 정함
- naive : 모든 predictive 가 독립이라는 가정 (P(x_1, x_2, ..., x_p|y=i) 대신 P(x_j|y=i) 이용)
- P(Y|X)=(likelihood * prior) / evidence = P(x_1, x_2, ..., x_p|y=i) * P(Y) / P(x_1, x_2, ..., x_p)
- shortage
    - 빈번한 0 (분자에 bias*prior 더하는 걸로 해결)
    - 종속성 있으면 안됨
- Both predictor and outcome variables should be categorical.
- Answering : 'Which category of predictor is most likely within each output category'

### 5.2 Discriminant analysis

- term
    - covariance / discriminant function / discriminant weight
- LDA(Linear Discriminant Analysis)
    - SS_내부 (그룹 안의 변동 측정) SS_사이(그룹 사이의 편차 측정)
    - SS_사이 / SS_내부 를 최대화 하는 선형 결합(w_x * x +w_z * z)찾기
    - linear discriminant function 로 클래스에 속할 가중치 혹은 점수를 구한다

### 5.3 Logistic regression

- Generalized linear model
    - f(x) = b0+b1X1+b2X2+...+bpXp
    - f(x) : 링크 함수 / f(x) 자리에 특별한 함수들이 들어가서 구체적인 회귀분석을 만든다!
        - linear regression : Y= b0+b1X1+b2X2+...+bpXp / logistic regression ln(p/(1-p))=b0+b1X1+b2X2+...+bpXp
    - ![images/logistic_regression.png](images/logistic_regression.png)

    - 해석 : 계수 bj= Xj에 대한 오즈비의 로그 값 → 계수가 1만큼 증가하면 오즈비가 exp(1) 만큼 증가!
- Similarities with Linear regression : Both assumes linear relationship between predictor and response variable
- Differences with Linear regression
    - Model fitting method(not RMSE) - MLE
    - Characteristics and analysis of residuals in the model
    - 출력이 이진변수다

### 5.4 Classification model evaluation

|     | y^=1 | y^=0 |
|-----|------|------|
| y=1 | TP   | FN   |
| y=0 | FP   | TN   |

- precision : Accuracy of positive results
    - 참양성 / 양성판정 = TP/(TP+FP)
- recall(=sensitivity) : Evaluates the model's ability to predict positive results
    - 참양성 / 전체 양성 = TP/(TP+FN)
- specificity : Evaluates the model's ability to predict negative results
    - 참음성 / 전체 음성 = TN/(TN+FP)
- ROC curve
    - Expresses the trade-off relationship between recall and specificity
    - specificity for x axis / recall for y axis
    - 효과적인 분류기라면 곡선이 왼쪽 상단으로 그려져야함
    - 비슷하게는 pr curve
- AUC(Area Under Curve)
    - 1 : 0을 1로 잘못 예측하는 경우가 없는 것
    - 최악의 경우는 0.5인 경우
- Lift
    - Measure how efficiently the model classifies 1 (가장 1로 분류될 가능성이 높은 것 부터 매 십분위마다 계산함)
    - 레코드를 무작위로 선택했다면 0.1% 정확도인데, 상위 10%에서 0.3%의 결과를 얻었다 = 3의 리프트(gain)
    - 랜덤 선택을 의미하는 대각선에 대한 누적 이득의 비율
    - Cumulative gains chart / lift curve / decile gain chart

### 5.5 Dealing with unbalanced data

- term
    - under sample(=down sampling) / over sample(=up sampling / using bootstrap)
    - up weight / down weight
    - data generation(SMOTE-synthetic minority oversampling technique : Find records similar to the upsampled record, and create a new composite record with a random weighted average of the original and neighbor records.)
- If there is an imbalance in the data, it is usually given a higher score for correctly classifying either side, and this value ratio should be reflected in the evaluation index.
