## 7. Unsupervised learning

### 7.1 PCA(Principal Component Analysis)

- term
    - principal component / loading / screeplot
- method
    - feature 의 covariance matrix → eigen value 가 최대일때의 eigen vector 가져옴 → 이 vector 전부 plot 시킴

### 7.2 K-means clustering

- Elbow method
    - set K
    - x axis - # of clusters / y axis - Variance explained (SS- (Sum((x_i-x^)^2+(y_i-y^)^2)) 클러스터 내부 제곱합)
- method
    1. initial cluster - random K points
    2. Each record is assigned to the cluster with the closest mean.
    3. Compute the new cluster average with the newly allocated records.

### 7.3 Hierarchical clustering

- term
    - dendrogram / dissimilarity
- Agglomerative algorithm
    - 유사한 클러스터들을 반복적으로 병합
    - method
        1. Create an initial cluster set of clusters consisting of only a single record for every record of data.
        2. Calculate the dissimilarity between all pairs of clusters.
        3. Merge two clusters with smallest dissimilarity
        4. Repeat merging until one cluster remains.
- dissimilarity
    - complete linkage - 가장 먼 두점 사이의 거리
    - single linkage - 최단 거리중 가장 가까운 두개 cluster 병합
    - average linkage - cluster 내 모든 점끼리의 거리 구해서 average 한걸 measure 로 활용
    - ward's method - cluster 간 병합을 가정하고 centeroid 를 그림, 그 center 로부터의 거리를 구함