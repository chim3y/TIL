## Overview of Text Retrieval Methods
* Design of ranking function f(q, d) pre-requires a computational definition of relevance(retrieval model) --> 쿼리 유사도, 확률모델, 확률 추론 모델 등
* 최신의 ranking function 은 아래의 것들에 의존하는 경향이 있음
	* Bag of words representation
	* Term Frequency(TF) and Document Frequency(DF) of words
	* Document length
 
* Retrieval model 형태
	* Similarity-based models(쿼리 유사도) : f(q, d)=similarity(q, d)
		* 질문과 doc 의 유사도로 함수
			* Vector space model 이 대표적
	* Probabilistic model(확률 모델) : f(d, q)=p(R=1|d, q), where R ∈{0, 1}
		* Classic probabilistic model
		* Language model
		* Divergence form randomness model
	* Probabilistic inference model(확률 추론 모델): f(q, d)=p(d--> q)
	* Axiomatic model : 좋은 함수라면 만족해야할 constraint 를 지정
		* Constraint 들을 조건으로 두고 그것에 맞는 함수들을 만드는 것 - 좋은 함수는 이걸 많이 만족하는 함수
	** 위의 각 모델들은 다른 컨셉에서 출발하지만 유사한 ranking function 과 variable 을 갖게 돼(신기하게도)

* Common form of state of the art retrieval model
	* Bag of word는 모든 search engine 에서 쓰이는 기법이자 assumption
		![ir1](images/2_1.PNG "ir1")
		"presidential campaign news"라는 걸 검색할 때에는 각 word 에 해당하는 것들에 대한 확률을 조합해서 전체 query 에 해당할 확률을 계산해
	* 이 방법 중에 tf/idf 등이 있을 수 있는 것

* 어떤 모델이 최선인가
	* 최적화 되었음을 가정하면 아래의 모델들이 성능이 비슷하게 좋음
		* Pivoted length normalization
		* BM25
		* Query likelihood
		* PL2
	* Bm25 가 유명하긴 함


