## AutoEncoder
* 대표적 비지도학습방법
* input -> encode -> decode -> output
```python
X = tf.placeholder(tf.float32, [None, n_input])
W_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))
b_encode = tf.Variable(tf.random_normal([n_hidden]))

encoder = tf.nn.sigmoid(
                tf.add(tf.matmul(X, W_encode), b_encode))
```
* encode : output 의 크기를 input 보다 작게 만들어서 정보 압축 --> 의미 있는 특성만 뽑아내게 함
* decode : 출력은 입력과 동일한 크기를 갖게 해서 입력과 동일한 output 을 만들게 함
* 특성치 추출 알고리즘, 히든레이어 구성으로 다양한 autoencoder 만들 수 있음
```python
W_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))
b_decode = tf.Variable(tf.random_normal([n_input]))
# 디코더 레이어 구성
# 이 디코더가 최종 모델이 됨
decoder = tf.nn.sigmoid(
                tf.add(tf.matmul(encoder, W_decode), b_decode))
```
* cost function 실측값, 디코딩 결과와의 차이로 계산
```python
cost = tf.reduce_mean(tf.pow(X - decoder, 2))
optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)
```
* 결과 확인
```python
samples = sess.run(decoder,
                   feed_dict={X: mnist.test.images[:sample_size]})
```