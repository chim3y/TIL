# 학습 전에 제대로 돌아가는지 확인하는 팁
	1. 맞는 손실함수를 찾아야
		a. 기대한 만큼의 loss function 값이 실제로 나오는지 확인해야함
		b. (ex cifar-10 데이터에서 softmax 쓰면 손실함수를 2.302로 기대할 수 있음(-ln(0.1)=2.302 / 각 클래스에 확률이 0.1로 분산)
	2. 정규화 강도를 올릴수록 손실 함수 값이 올라가야 함
	3. 자료의 작은 부분 집합으로 과적합 해봐야
		a. 20개 자료정도로 0cost 가 나오는지 확인해봐야해(정규화 강도를 0으로 해 놓고)
		b. 작은 자료에서 확인이 제대로 안되면 전체 과정이 무가치함
# 학습 과정 확인(babysitting the learning process)
