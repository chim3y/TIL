## 데이터 스트림 처리를 위한 기술
### 스트리밍 처리 --> 대용량 분산 큐 --> 머신러닝 --> 이벤트 처리
* 스트리밍 처리
	* 데이터 스트림을 여러 경로로 분산하여 각 단계별로 처리(구매패턴 분석, 구매패턴 검증, 등)하는 워크플로우 기능 필요(storm 혹은 spark)
* 대용량 분산 큐
	* 대용량으로 여러 경로 통해서 들어오는 데이터를 수집하기 위한 터널 필요(비동기 처리를 위한 큐)
	* 디용량 지원성이 필수적
	* kafka
* 머신러닝
	* Apache mahout, MS Asure ml, spark ml
* 이벤트 처리
	* 특정 조건에 대해서 이벤트를 발생시키는 것 = CEP(Complex Event Processing)
	* EDA(Event Driven Architecture) : 이를 구현한 아키텍쳐
	* 이러한 이벤트 처리 프레임웍으로 JBoss Drool, Esper 와 같은게 있는 것

### Apache Storm
* 용어
	* tuple, stream, spout, bolt
	* 실시간으로 생성되어 전달되는 데이터 구조체 --> Tuple
		* 데이터가 생거나, 처리되는 것을 튜플이 생서, 처리 되었다고 함
		* 모든 종류의 데이터 타입을 지원하고, CSV 로 구상됨
	* 이 비동기로 생성된 tuple 을 로봇에게 던져지는데, 이를 --> Stream
		* 보통 여러대의 로봇 이용 / 데이터 사용할때마다 이리저리 처리해달라 던져대서 무질서한 흐름 형성
	* 튜플을 생성해서 로봇에 던지는 주체 --> Spout
		* 흐름(stream)을 만드는 주둥아리...
	* 처리하는 로봇 --> 볼트
		* 던져진 튜플을 받아 유의미한 자료를 만들어냄
		




http://bcho.tistory.com/989
http://c-o-e.tistory.com/37