## Sampling from a data stream
### Sampling a fixed proportion
* Naive Solution
	* (user, query, time)의 stream data일때
	* hash function 로 각 query 마다 random integer 부여하고, 특정 수 아니면 다 버린다
	- stream 양이 많아지면 sample 의 양도 많아진다는 단점이 있음
	- 중복 검색어 비율 등을 구할 때에 잘못된 값을 낼 수 있음
	* 중복 검색어의 비율을 구하고싶다면?
		- user 가 평균적으로, x 개 query 를 한번, d개 query 를 2번 던진다면, 중복 검색어 비율의 참값은 d/(x+d)
		- 근데 naive 하게, 10%의 query 만 남겨뒀다면, d의 중복값이 다 들어갈 비율은 d/100(=(1/10)\*(1/10)\*d) 일 것
		- duplicate 된 애들 중에서, 18d/100(=((1/10)\*(9/10)+(1/10)\*(9/10))\*d)개는, 1번만 count 됐을 것
		- 즉, fixed proportion 으로 추출했다면, 중복 검색어의 비율은 (d/(10x+19d)) (=(d/100)/((x/10)+(d/100)+(18d/100))) 로 잘못나오게 될 것
* **Generalized solution**
	* query 가 아닌 user 를 sample 하는 방식
	* (user, query, time)에서 key 를 user 로 둔다
	* key 를 k 개 bucket 에 uniformly hashing
	* 전체 query 의 a/b 비율을 꼽는다면, b 개의 bucket 중, a 개를 sample 하는 것


### Sampling a fixed-size sample
* overview
	* 메인 메모리에 올리는게 가능한정도만 남기는 형태일 것
	* fixed size 로 sampling 하면서도, 모든 데이터가 같은 확률로 뽑힐 수 있게 할 수 있을까
		- size s 을 sampling 한다면 s가 5일때와 7일때 특정 수가 등장하는 비율이 다르게 나올거야 --> 이런 문제를 해결하려면?
* **Reservoir Sampling**
	* 들어온 순서대로 s 개 element 저장할수 있다고 치면, 
	* n-1(n>s)개의 element 를 봤다고 할때, n 번째 element 가 도착한다면
	* --> s/n 의 확률로, n 을 pick 하고 아니면 버린다
	* 이 n 번째 element 가 pick 된다면 s개의 element 중 하나를 replace 한다.
* Reservoir Sampling 증명(inductive step)
	1. n번째 element 까지 했을때에, sample S 가 포함한 각 element 의 확률이 s/n 이라면
	2. element n+1이 